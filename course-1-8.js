import { Client, GatewayIntentBits } from 'discord.js';
import OpenAI from 'openai';
import 'dotenv/config';
import { encoding_for_model } from 'tiktoken';

// =========== 1. åˆå§‹åŒ– Discord Client ==========
const bot = new Client({
  intents: [
    GatewayIntentBits.Guilds,
    GatewayIntentBits.GuildMessages,
    GatewayIntentBits.MessageContent,
  ],
});

// =========== 2. åˆå§‹åŒ– OpenAI ==========
const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY 
});   

// =========== 3. ç™»å…¥ Discord ==========
const token = process.env.DISCORD_BOT_TOKEN;

await bot.login(token);

// =========== 4. Bot æˆåŠŸä¸Šç·š ==========
bot.once('ready', () => {
  console.log(`ğŸ¤– å·²ç™»å…¥ï¼š${bot.user?.tag}`);
});

// =========== 5. æ”¶åˆ°è¨Šæ¯ â†’ äº¤çµ¦ GPT æ€è€ƒ â†’ å›è¦† ==========
// ç²¾ç¢ºè¨ˆç®— Token æ•¸é‡çš„å‡½æ•¸
function countTokens(messages, model = "gpt-4.1-mini") {
  // 1. å»ºç«‹å°æ‡‰ AI æ¨¡å‹çš„ç·¨ç¢¼å™¨
  const encoder = encoding_for_model(model);
  let totalTokens = 0;
  
  // 2. é€ä¸€è¨ˆç®—æ¯å€‹è¨Šæ¯çš„ Token æ•¸é‡
  for (const message of messages) {
    totalTokens += encoder.encode(message.content).length;
    totalTokens += 4; // æ¯å€‹è¨Šæ¯é‚„æœ‰æ ¼å¼ä¸Šçš„é–‹éŠ·ï¼ˆroleã€content ç­‰çµæ§‹ï¼‰
  }
  
  // 3. é‡‹æ”¾è¨˜æ†¶é«”ï¼ˆé‡è¦ï¼é¿å…è¨˜æ†¶é«”æ´©æ¼ï¼‰
  encoder.free();
  return totalTokens;
}

// è¨Šæ¯æˆªæ–·å‡½æ•¸
function smartTruncateMessages(messages, maxTokens = 900000) {
  let currentTokens = countTokens(messages);
  
  // å¦‚æœ Token æ•¸é‡è¶…éé™åˆ¶ï¼Œå°±é–‹å§‹ã€Œå¿˜è¨˜ã€èˆŠå°è©±
  while (currentTokens > maxTokens && messages.length > 1) {
    // æ‰¾å‡º system è¨Šæ¯ï¼ˆAI çš„è§’è‰²è¨­å®šï¼‰
    const systemMessage = messages.find(m => m.role === 'system');
    
    // ç§»é™¤æœ€èˆŠçš„å°è©±ï¼Œä½†ä¿ç•™ system è¨Šæ¯
    messages = messages.filter((m, i) => !(i > 0 && m.role !== 'system'));
    
    // ç¢ºä¿ system è¨Šæ¯æ°¸é åœ¨æœ€å‰é¢
    if (systemMessage) {
      messages = [systemMessage, ...messages.slice(1)];
    }
    
    // é‡æ–°è¨ˆç®— Token æ•¸é‡
    currentTokens = countTokens(messages);
  }
  
  return messages;
}

bot.on("messageCreate", async (message) => {
  if (message.author.bot) return;

  const recentMessages = await message.channel.messages.fetch({ limit: 10 });

  let messages = recentMessages
    .sort((a, b) => a.createdTimestamp - b.createdTimestamp)
    .map((msg) => ({
      role: msg.author.bot ? "assistant" : "user",
      content: msg.content,
    })); 

  // ä½¿ç”¨æˆ‘å€‘çš„æ™ºæ…§å‹ Token ç®¡ç†
  messages = smartTruncateMessages(messages, 100000); // é™åˆ¶ 10 è¬ Token

  console.log(`å°è©±ä½¿ç”¨äº† ${countTokens(messages)} å€‹ Token`);

  const response = await openai.responses.create({
      model: "gpt-4.1-mini",
      input: messages
  });
  
  await message.reply(response.output_text);
});